{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0234530a-e5ec-4301-9e62-a82af681a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Impor packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys, re, spacy\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_md')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e795012-4df5-4c1d-b050-9f22cabff996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### creating ticker list\n",
    "ticker_list = ['NVDA.p','MA.p', 'KO.p', 'TD.p', 'TSLA.p', 'GS.p', 'JNJ.p', 'SBUX.p', 'NVO.p', 'INTU.p', 'NFLX.p', 'BX.p', 'LLY.p', 'PEP.p', 'EBAY.p', 'SAP.p', 'FB.p', 'ABBV.p', 'CHTR.p', 'MRK.p', 'BMY.p', 'ADBE.p', 'ORCL.p', 'F.p', 'NKE.p', 'BKNG.p', 'GM.p', 'UPS.p', 'T.p', 'AMD.p', 'CMCSA.p', 'DIS.p', 'MDT.p', 'SNY.p', 'INTC.p', 'MS.p', 'HON.p', 'DUK.p', 'BLK.p', 'TGT.p', 'CSCO.p', 'TMUS.p', 'UNH.p', 'WMT.p', 'AXP.p',  'FDX.p', 'MCD.p', 'GOOG.p', 'ASML.p', 'V.p', 'BAC.p', 'RY.p', 'AMT.p', 'WFC.p', 'XOM.p', 'MET.p', 'QCOM.p', 'PM.p', 'CVS.p', 'MSFT.p', 'AMZN.p', 'IBM.p', 'VZ.p', 'ACN.p', 'C.p', 'HD.p', 'NVS.p', 'ISRG.p', 'AZN.p', 'CRM.p', 'PG.p', 'AAPL.p', 'TMO.p', 'TSM.p', 'EL.p', 'DHR.p', 'TXN.p', 'JPM.p', 'PFE.p', 'SE.p', 'CVX.p', 'NEE.p', 'AMGN.p', 'COST.p', 'BA.p', 'ABT.p', 'MCO.p', 'LOW.p', 'LMT.p', 'UNP.p']\n",
    "len(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c3fa95-c1dc-4fa6-af73-906e550c2070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detta 채r v책ra tickers, ['CMCSA.p', 'DIS.p', 'MDT.p', 'SNY.p', 'INTC.p', 'MS.p', 'HON.p', 'DUK.p', 'BLK.p', 'TGT.p']\n"
     ]
    }
   ],
   "source": [
    "tl4 = ticker_list[30:40]\n",
    "print(f\"Detta 채r v책ra tickers, {tl4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9491ee-ab5a-4bef-915d-63ffbb9f68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change ticker to be loaded\n",
    "tl = tl4[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3c1627-8dcd-4d01-8053-9def4b38c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load transcripts from ticker \"tl\"\n",
    "transcripts = pickle.load(open( str(\"./shared/Transcripts/\"+tl), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d9d028-69c2-4eb8-b449-9c0f3347a79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transctipts to list\n",
    "transcripts_texts = []\n",
    "\n",
    "# times to list\n",
    "times = []\n",
    "\n",
    "for t in transcripts:\n",
    "    text = ''\n",
    "    for speech in t['transcript']:\n",
    "        text = str(text + ' '+ speech['speech'][0])\n",
    "\n",
    "    transcripts_texts.append(text)\n",
    "    \n",
    "    times.append(t['time'])\n",
    "    \n",
    "len(transcripts_texts), len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ad6142-d7b5-486f-94dd-bf6a7e14e53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Getting Loughran & McDonald (LM) Wordlists\n",
    "LM_negative=pd.read_excel('./shared/Lecture 3 Text Analysis/LoughranMcDonald_SentimentWordLists_2018.xlsx', sheet_name='Negative', header=None)\n",
    "LM_positive=pd.read_excel('./shared/Lecture 3 Text Analysis/LoughranMcDonald_SentimentWordLists_2018.xlsx', sheet_name='Positive', header=None)\n",
    "LM_uncertainty=pd.read_excel('./shared/Lecture 3 Text Analysis/LoughranMcDonald_SentimentWordLists_2018.xlsx', sheet_name='Uncertainty', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2c0a52-0afa-4f9d-94b7-028e491e2092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 2355, 297)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing wordlists\n",
    "LM_positive=LM_positive.T.values.tolist()[0]\n",
    "LM_negative=LM_negative.T.values.tolist()[0]\n",
    "LM_uncertainty=LM_uncertainty.T.values.tolist()[0]\n",
    "len(LM_positive), len(LM_negative), len(LM_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c46fcf-0531-4a16-a615-5933cd1a968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining process function that removes punctuation, stop words and spaces\n",
    "def process_spacy_doc(text):\n",
    "    # Tokenize\n",
    "    # Remove stop words, spaces, punctuation\n",
    "    # Lemmatize\n",
    "    # Convert to lower case\n",
    "    words=[\n",
    "        word.lemma_.lower()                 # Lemmatize and lower case\n",
    "        for word in nlp(text)          # Tokenize\n",
    "        if not (\n",
    "            word.is_space                   # Remove spaces\n",
    "            or word.is_stop                 # Remove stop words\n",
    "            or word.is_punct                # Remove punctuation\n",
    "        )\n",
    "    ]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc1b824-6c00-40e8-b9a1-21374fa92f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 2353, 288)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "\n",
    "LM_positive=process_spacy_doc(' '.join(LM_positive))\n",
    "LM_negative=process_spacy_doc(' '.join(LM_negative))\n",
    "LM_uncertainty=process_spacy_doc(' '.join(LM_uncertainty))\n",
    "len(LM_positive), len(LM_negative), len(LM_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a004def-b9d3-4762-a475-3707e7c6eda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 1341, 194)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_positive=set(process_spacy_doc(' '.join(LM_positive)))\n",
    "LM_negative=set(process_spacy_doc(' '.join(LM_negative)))\n",
    "LM_uncertainty=set(process_spacy_doc(' '.join(LM_uncertainty)))\n",
    "len(LM_positive), len(LM_negative), len(LM_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f9da21-c0ab-44e6-8d79-dc9d663ee564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_transcript(text):\n",
    "    # Running the function we created earlier that remove stopwords, spaces and so on... \n",
    "    words = process_spacy_doc(text)\n",
    "\n",
    "        \n",
    "    # This is the same as above as well. \n",
    "    # We the save the amount of words for later. This will show us how many % of the words are e.g. positive. \n",
    "    number_of_words=len(words)\n",
    "    \n",
    "    counts=Counter(words)\n",
    "\n",
    "    keys=set(counts.keys())\n",
    "\n",
    "    pos = round((sum([counts[k] for k in (keys & LM_positive)]) / number_of_words), 4)\n",
    "    neg = round((sum([counts[k] for k in (keys & LM_negative)]) / number_of_words), 4)\n",
    "    unc = round((sum([counts[k] for k in (keys & LM_uncertainty)]) / number_of_words), 4)\n",
    "    \n",
    "    return(pos, neg, unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9c8cf3-55dd-4984-b48d-1fdf353f73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "0 83463\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "2 120502\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "28 101556\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "30 94091\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "34 120102\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "42 108972\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "46 108467\n",
      "\n",
      "TOO LONG .... going to make it shorter\n",
      "47 129245\n"
     ]
    }
   ],
   "source": [
    "## Testing if transcripts are to long and then shortening it\n",
    "for i in range(len(transcripts_texts)):    \n",
    "    if (len(transcripts_texts[i]) > 80000):\n",
    "        print()\n",
    "        print('TOO LONG .... going to make it shorter')\n",
    "        print(i, len(transcripts_texts[i]))\n",
    "        transcripts_texts[i] = transcripts_texts[i][:80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f88bb6-35b3-4bb3-bf54-86a7482ac128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe to save all scores.\n",
    "sentiment_scores = pd.DataFrame(columns=['pos', 'neg', 'unc'])\n",
    "\n",
    "# Loop through all texts \n",
    "for texts in transcripts_texts:\n",
    "    # Calls our scoring function and gets 3 scores back\n",
    "    scores = score_transcript(texts)\n",
    "    \n",
    "    # This creates a new dataframe with one line of 3 scores \n",
    "    # and adds it to the bottom of our dataframe that stores all scores\n",
    "    sentiment_scores = pd.concat([sentiment_scores, pd.DataFrame([np.array(scores)], columns=['pos', 'neg', 'unc'])]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ccfd5-dcb8-4809-8410-b16d7e3a84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df7925-33b4-42a3-8910-212a07594708",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores.index = pd.to_datetime(times)\n",
    "\n",
    "# Lets also reverse the order so that old is first. Makes it easier to merge. \n",
    "# https://stackoverflow.com/a/3940137\n",
    "sentiment_scores = sentiment_scores[::-1]\n",
    "\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c1cf1-0e1d-415e-91c2-b33c77c13e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores.plot(figsize=(14,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f1115-3fc7-4357-8770-1cbfe82462ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "sentiment_scores.to_csv(\"./csv/\"+tl+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c9fe4-8b66-4470-a2e8-ada587d55810",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abbf1c-49fe-48af-82ad-94522b29b0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
